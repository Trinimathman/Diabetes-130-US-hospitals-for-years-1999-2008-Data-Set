{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOoqaLj5oK8V2E2KWQql3+c",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Trinimathman/Diabetes-130-US-hospitals-for-years-1999-2008-Data-Set/blob/main/Brian_Maurice_88843650_Section3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PAKoZGIwkwmq"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.decomposition import NMF\n",
        "from sklearn.decomposition import LatentDirichletAllocation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "data = pd.read_csv('DisneylandReviews_cleaned.csv')"
      ],
      "metadata": {
        "id": "EtrzhtfulHmW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Topic Modeling with NMF"
      ],
      "metadata": {
        "id": "nUVh2wPslL-w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the number of topics\n",
        "num_topics = 20\n",
        "max_iter = 500  # set the maximum number of iterations to 500\n",
        "\n",
        "# Set the parameters for the vectorizer models\n",
        "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2)\n",
        "cv_vectorizer = CountVectorizer(max_df=0.95, min_df=2)"
      ],
      "metadata": {
        "id": "WiVzU_hwlPnw"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the document-term matrix using the vectorizer models\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(data['review_content_clean'])\n",
        "cv_matrix = cv_vectorizer.fit_transform(data['review_content_clean'])\n",
        "\n",
        "# Fit the NMF model using the document-term matrix\n",
        "tfidf_model = NMF(n_components=num_topics, max_iter=max_iter, random_state=42)\n",
        "cv_model = NMF(n_components=num_topics, random_state=42)\n",
        "\n",
        "tfidf_topic_matrix = tfidf_model.fit_transform(tfidf_matrix)\n",
        "cv_topic_matrix = cv_model.fit_transform(cv_matrix)"
      ],
      "metadata": {
        "id": "bewxPyEelUZY"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the document-term matrix using the vectorizer models\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(data['review_content_clean'])\n",
        "cv_matrix = cv_vectorizer.fit_transform(data['review_content_clean'])\n",
        "\n",
        "# Fit the NMF model using the document-term matrix\n",
        "tfidf_model = NMF(n_components=num_topics, random_state=42)\n",
        "cv_model = NMF(n_components=num_topics, random_state=42)\n",
        "\n",
        "tfidf_topic_matrix = tfidf_model.fit_transform(tfidf_matrix)\n",
        "cv_topic_matrix = cv_model.fit_transform(cv_matrix)"
      ],
      "metadata": {
        "id": "rsp33gMzlaEi"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the top 10 words using TF-IDF Model\n",
        "\n",
        "tfidf_feature_names = tfidf_vectorizer.get_feature_names_out()\n",
        "\n",
        "for topic_idx, topic in enumerate(tfidf_model.components_):\n",
        "    print(\"Topic %d:\" % (topic_idx))\n",
        "    print(\" \".join([tfidf_feature_names[i] for i in topic.argsort()[:-11:-1]]))\n",
        "    \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxLig1Nylzyy",
        "outputId": "4d83e0df-1fdc-4750-8a1c-252744d30760"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic 0:\n",
            "disney world florida magic small smaller like land orlando walt\n",
            "Topic 1:\n",
            "pas fast get use earli app system make line ticket\n",
            "Topic 2:\n",
            "child famili young adult age small experi would ride recommend\n",
            "Topic 3:\n",
            "show parad firework night miss mickey see watch charact lion\n",
            "Topic 4:\n",
            "kong hong disneyland train mtr small compar pari smaller one\n",
            "Topic 5:\n",
            "day one two spent enough spend everyth whole full need\n",
            "Topic 6:\n",
            "great famili ride experi food still atmospher weather halloween age\n",
            "Topic 7:\n",
            "food good expens price queue water ticket drink bring take\n",
            "Topic 8:\n",
            "place earth happiest truli magic amaz best happi say come\n",
            "Topic 9:\n",
            "ride line wait long mountain minut hour space went close\n",
            "Topic 10:\n",
            "visit disneyland first attract hk must worth still experi hongkong\n",
            "Topic 11:\n",
            "park theme california adventur hopper attract hotel walk ocean around\n",
            "Topic 12:\n",
            "kid adult like littl young heart ride older place charact\n",
            "Topic 13:\n",
            "love disneyland everi everyth absolut amaz charact back come ride\n",
            "Topic 14:\n",
            "fun lot much still age famili disneyland ride see thing\n",
            "Topic 15:\n",
            "alway staff friendli clean help member cast disneyland magic amaz\n",
            "Topic 16:\n",
            "go back disneyland get crowd would peopl want dont cant\n",
            "Topic 17:\n",
            "enjoy realli ride thoroughli experi nice much attract trip famili\n",
            "Topic 18:\n",
            "year old daughter new trip son ago last took sinc\n",
            "Topic 19:\n",
            "time first wait app wonder trip christma next best famili\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the top 10 words using Count Vectorizer Model\n",
        "\n",
        "cv_feature_names = cv_vectorizer.get_feature_names_out()\n",
        "\n",
        "    \n",
        "for topic_idx, topic in enumerate(cv_model.components_):\n",
        "    print(\"Topic %d:\" % (topic_idx))\n",
        "    print(\" \".join([cv_feature_names[i] for i in topic.argsort()[:-11:-1]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVhhOe-dvv6x",
        "outputId": "b1e752a5-8e11-4e03-b385-a90e7e3e952e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic 0:\n",
            "disney park disneyland visit time year ride world go like\n",
            "Topic 1:\n",
            "disneyland day disney place ride park visit kid great enjoy\n",
            "Topic 2:\n",
            "ride mountain day time park wait get space show went\n",
            "Topic 3:\n",
            "park ride get time day pas food go disneyland fast\n",
            "Topic 4:\n",
            "line park time day ride get peopl go wait crowd\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this case, we may have chosen 5 topics based on prior knowledge of the dataset or based on the results of initial exploratory data analysis. It is also common to try different numbers of topics, such as 3, 5, 10, or 20, and compare the results to choose the best number of topics for the analysis."
      ],
      "metadata": {
        "id": "_EGwp9fRmTDc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Topic Modeling with LDA"
      ],
      "metadata": {
        "id": "496QNM18mgCb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the number of topics\n",
        "num_topics = 5\n",
        "\n",
        "# Set the parameters for the vectorizer models\n",
        "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2)\n",
        "cv_vectorizer = CountVectorizer(max_df=0.95, min_df=2)"
      ],
      "metadata": {
        "id": "pvM-wJsNmkWi"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the document-term matrix using the vectorizer models\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(data['review_content_clean'])\n",
        "cv_matrix = cv_vectorizer.fit_transform(data['review_content_clean'])\n",
        "\n",
        "# Fit the LDA model using the document-term matrix\n",
        "tfidf_model = LatentDirichletAllocation(n_components=num_topics, random_state=42)\n",
        "cv_model = LatentDirichletAllocation(n_components=num_topics, random_state=42)\n",
        "\n",
        "tfidf_topic_matrix = tfidf_model.fit_transform(tfidf_matrix)\n",
        "cv_topic_matrix = cv_model.fit_transform(cv_matrix)"
      ],
      "metadata": {
        "id": "sd7CaLBSmrgt"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the top 10 words using TF-IDF Model\n",
        "tfidf_feature_names = tfidf_vectorizer.get_feature_names_out()\n",
        "\n",
        "for topic_idx, topic in enumerate(tfidf_model.components_):\n",
        "    print(\"Topic %d:\" % (topic_idx))\n",
        "    print(\" \".join([tfidf_feature_names[i] for i in topic.argsort()[:-11:-1]]))\n",
        "    \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7xZr3Rhmyjp",
        "outputId": "3fd19016-9ec3-4890-c421-64c67932710b"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic 0:\n",
            "dislik miner niec amor accompani pension 61 honk arena anyhow\n",
            "Topic 1:\n",
            "place disneyland kid love visit great disney enjoy fun day\n",
            "Topic 2:\n",
            "ride mountain love show disneyland great park disney parad day\n",
            "Topic 3:\n",
            "park ride day time disneyland disney get go line visit\n",
            "Topic 4:\n",
            "gay disneypark 3hr knot utah disneland john 36 glori itso\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the top 10 words using Count Vectorizer Model\n",
        "\n",
        "cv_feature_names = cv_vectorizer.get_feature_names_out()\n",
        "\n",
        "for topic_idx, topic in enumerate(cv_model.components_):\n",
        "    print(\"Topic %d:\" % (topic_idx))\n",
        "    print(\" \".join([cv_feature_names[i] for i in topic.argsort()[:-11:-1]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7oPIxAMwrzA",
        "outputId": "6a2442e2-59db-4b35-c71f-92dcca273f11"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic 0:\n",
            "disney park disneyland visit time year ride world go like\n",
            "Topic 1:\n",
            "disneyland day disney place ride park visit kid great enjoy\n",
            "Topic 2:\n",
            "ride mountain day time park wait get space show went\n",
            "Topic 3:\n",
            "park ride get time day pas food go disneyland fast\n",
            "Topic 4:\n",
            "line park time day ride get peopl go wait crowd\n"
          ]
        }
      ]
    }
  ]
}